# Environment variables for Sentinel Agent

# ============================================
# 环境模式配置
# ============================================
# ENV_MODE: 环境模式
#   - competition: 比赛模式（调用API获取赛题列表）
ENV_MODE=competition

# ============================================
# 比赛配置（仅在 competition 模式下需要）
# ============================================
# 比赛平台 API 基础 URL
COMPETITION_BASE_URL=http://xxxx:8000

# 比赛 API 认证令牌（请从比赛平台获取）
COMPETITION_API_TOKEN=8695e34c-xxxxx

# ============================================
# 目标配置
# ============================================
# 注意：所有赛题目标都通过比赛 API 获取，不再需要单独配置 TARGET_IP

# Docker Configuration
DOCKER_CONTAINER_NAME=kali-pentest

# ============================================
# LLM 配置
# ============================================
# LLM
DEEPSEEK_BASE_URL="https://api.lkeap.cloud.tencent.com/v1"
DEEPSEEK_API_KEY="sk-xxxx"

SILICONFLOW_BASE_URL="https://api.siliconflow.cn/v1"
SILICONFLOW_API_KEY="sk-xxxxx"
SILICONFLOW_MODEL="MiniMaxAI/MiniMax-M2"


LANGFUSE_SECRET_KEY = "sk-lf-xxxxx"
LANGFUSE_PUBLIC_KEY = "pk-lf-xxxxx"
LANGFUSE_HOST = "http://127.0.0.1:3000" # 🇺🇸 US region

SANDBOX_ENABLED=false


# ============================================
# Agent 运行配置
# ============================================
# 最大尝试次数（单题）- 默认 70 次
MAX_ATTEMPTS=70

# LangGraph 递归限制（建议比 MAX_ATTEMPTS 大 10）- 默认 80
RECURSION_LIMIT=80

# 单题超时时间（秒）- 默认 15 分钟
SINGLE_TASK_TIMEOUT=900

# 调试模式：是否允许重新攻击已解决的题目（true/false）
# - true: 调试模式，会重新攻击已解决的题目
# - false: 正式模式，跳过已解决的题目
DEBUG_ALLOW_RESOLVED=false

# 定时任务配置（可选）
FETCH_INTERVAL_SECONDS=600     # 拉取题目间隔（默认 10 分钟）
MONITOR_INTERVAL_SECONDS=300   # 状态监控间隔（默认 5 分钟）

# ============================================
# 工具输出总结配置（优化 Token 消耗）
# ============================================
# 是否启用工具输出总结（true/false）
# - true: 对长输出使用 LLM 总结，减少 token 消耗
# - false: 直接返回完整输出
ENABLE_TOOL_SUMMARY=true

# 工具输出总结阈值（字符数）
# 超过此长度的输出会被总结，默认 5000 字符
TOOL_SUMMARY_THRESHOLD=5000

# ============================================
# 智能失败检测配置（提升准确率）
# ============================================
# 是否启用 LLM 语义失败检测（true/false）
# - true: 使用 LLM 进行语义层面的失败检测（推荐，准确率 95%+）
# - false: 使用关键字匹配（准确率 60-70%，但无额外成本）
#
# 成本分析：
#   - 每次检测消耗约 500 tokens（输入 300 + 输出 200）
#   - 使用 DeepSeek：约 $0.0001/次
#   - 每题约 15 次检测 = $0.0015
#   - 收益：避免重复失败，节省 6-8 分钟，成功率提升 20-30%
ENABLE_SMART_FAILURE_DETECTION=true
