# Environment variables for Sentinel Agent

# ============================================
# 环境模式配置
# ============================================
# ENV_MODE: 环境模式
#   - competition: 比赛模式（调用API获取赛题列表）
ENV_MODE=competition

# ============================================
# 比赛配置（仅在 competition 模式下需要）
# ============================================
# 比赛平台 API 基础 URL
COMPETITION_BASE_URL=http://xxxx:8000

# 比赛 API 认证令牌（请从比赛平台获取）
COMPETITION_API_TOKEN=8695e34c-xxxxx

# ============================================
# 目标配置
# ============================================
# 注意：所有赛题目标都通过比赛 API 获取，不再需要单独配置 TARGET_IP

# Docker Configuration
DOCKER_CONTAINER_NAME=kali-pentest

# ============================================
# LLM 配置
# ============================================
# LLM
DEEPSEEK_BASE_URL="https://api.lkeap.cloud.tencent.com/v1"
DEEPSEEK_API_KEY="sk-xxxx"

SILICONFLOW_BASE_URL="https://api.siliconflow.cn/v1"
SILICONFLOW_API_KEY="sk-xxxxx"
SILICONFLOW_MODEL="MiniMaxAI/MiniMax-M2"


LANGFUSE_SECRET_KEY = "sk-lf-xxxxx"
LANGFUSE_PUBLIC_KEY = "pk-lf-xxxxx"
LANGFUSE_HOST = "http://127.0.0.1:3000" # 🇺🇸 US region

SANDBOX_ENABLED=false


# ============================================
# Agent 运行配置
# ============================================
# 最大尝试次数（单题）- 默认 70 次
MAX_ATTEMPTS=70

# LangGraph 递归限制（建议比 MAX_ATTEMPTS 大 10）- 默认 80
RECURSION_LIMIT=80

# 单题超时时间（秒）- 默认 15 分钟
SINGLE_TASK_TIMEOUT=900

# 调试模式：是否允许重新攻击已解决的题目（true/false）
# - true: 调试模式，会重新攻击已解决的题目
# - false: 正式模式，跳过已解决的题目
DEBUG_ALLOW_RESOLVED=false

# 定时任务配置（可选）
FETCH_INTERVAL_SECONDS=600     # 拉取题目间隔（默认 10 分钟）
MONITOR_INTERVAL_SECONDS=300   # 状态监控间隔（默认 5 分钟）

# ============================================
# 工具输出总结配置（优化 Token 消耗）
# ============================================
# 是否启用工具输出总结（true/false）
# - true: 对长输出使用 LLM 总结，减少 token 消耗
# - false: 直接返回完整输出
ENABLE_TOOL_SUMMARY=true

# 工具输出总结阈值（字符数）
# 超过此长度的输出会被总结，默认 3000 字符（从 5000 降低）
TOOL_SUMMARY_THRESHOLD=3000

# 工具输出最大总结长度（字符数）
# 超过此长度的输出会直接截断，不再总结（避免浪费 token）
# 默认 5000 字符（从 10000 降低）
MAX_SUMMARY_LENGTH=5000

# ============================================
# 上下文管理配置（防止上下文超限）
# ============================================
# 最大历史消息数（保留最近 N 条消息）
# 默认 10 条（从 20 条降低，避免 DeepSeek 上下文超限）
#
# 说明：
#   - 系统会保留 1 条自动侦察结果 + N 条最近的历史消息
#   - 每条消息可能包含工具输出、LLM 响应、Advisor 建议等
#   - DeepSeek 上下文限制约 32K-64K tokens
#   - 建议值: 5-15 条（根据题目复杂度调整）
#
# 调试建议：
#   - 如果遇到 "input length too long" 错误，降低此值（如 5）
#   - 如果 Agent 遗忘历史信息，提高此值（如 15）
MAX_HISTORY_MESSAGES=10

# ============================================
# 智能失败检测配置（提升准确率）
# ============================================
# 是否启用 LLM 语义失败检测（true/false）
# - true: 使用 LLM 进行语义层面的失败检测（推荐，准确率 95%+）
# - false: 使用关键字匹配（准确率 60-70%，但无额外成本）
#
# 成本分析：
#   - 每次检测消耗约 500 tokens（输入 300 + 输出 200）
#   - 使用 DeepSeek：约 $0.0001/次
#   - 每题约 15 次检测 = $0.0015
#   - 收益：避免重复失败，节省 6-8 分钟，成功率提升 20-30%
ENABLE_SMART_FAILURE_DETECTION=true

# ============================================
# 自动 FLAG 提交配置（兜底策略）
# ============================================
# 是否启用自动 FLAG 提取和提交（true/false）
# - true: 当 LLM 找到 FLAG 但未正确调用 submit_flag 时，系统自动提交
# - false: 完全依赖 LLM 调用 submit_flag 工具
#
# 使用场景：
#   - LLM 找到了 FLAG 但错误地使用 execute_python_poc 打印
#   - LLM 在注释中写了 submit_flag 调用但未实际执行
#   - LLM 理解能力不足，无法正确使用工具
#
# 工作原理：
#   1. 工具执行后，自动扫描输出中的 FLAG（格式：flag{...} 或 FLAG{...}）
#   2. 如果检测到 FLAG 且 LLM 未调用 submit_flag，自动提交
#   3. 提交成功后立即结束任务，避免浪费时间
#
# 推荐设置：true（可显著提升成功率，避免因 LLM 理解问题导致的失败）
AUTO_SUBMIT_FLAG=true

