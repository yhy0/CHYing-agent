"""
å¤š Agent åä½œå›¾ V2ï¼ˆä¸‰å±‚æ¶æ„ï¼‰
=====================================

ä¸‰å±‚æ¶æ„ï¼š
- è§„åˆ’å±‚ï¼šAdvisor Agent (MiniMax) + Main Agent (DeepSeek) - åªè´Ÿè´£è§„åˆ’ä¸å†³ç­–
- æ‰§è¡Œå±‚ï¼šPoC Agent + Docker Agent - ä¸“æ³¨æ‰§è¡Œ
- çŸ¥è¯†å±‚ï¼šSkills (SKILL.md) - æŒ‰éœ€åŠ è½½æ¼æ´çŸ¥è¯†åº“

æ¶æ„å›¾ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        è§„åˆ’å±‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ Advisor      â”‚ â”€â”€â”€â”€â”€â”€> â”‚ Main Agent   â”‚                   â”‚
â”‚  â”‚ (MiniMax)    â”‚ æä¾›å»ºè®® â”‚ (DeepSeek)   â”‚                   â”‚
â”‚  â”‚ +SkillsåŠ è½½  â”‚         â”‚ è§„åˆ’ä¸å†³ç­–    â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚ åˆ†å‘ä»»åŠ¡
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ‰§è¡Œå±‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ PoC Agent    â”‚         â”‚ Docker Agent â”‚                   â”‚
â”‚  â”‚ Pythonè„šæœ¬   â”‚         â”‚ Kaliå·¥å…·     â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä½œè€…ï¼šCHYing
æ—¥æœŸï¼š2025-12-10
"""
import asyncio
import time
import os
import logging
from typing import Literal, Optional
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_core.language_models import BaseChatModel
from langchain_core.messages import SystemMessage, AIMessage, HumanMessage, ToolMessage
from langchain_core.runnables import RunnableConfig

from chying_agent.state import PenetrationTesterState
from chying_agent.tools import get_all_tools
from chying_agent.common import log_system_event, log_agent_thought
from chying_agent.langmem_memory import get_memory_store, get_all_memory_tools
from chying_agent.utils.rate_limiter import get_rate_limiter
from chying_agent.utils.util import retry_llm_call
from chying_agent.utils.failure_detector import detect_failure_with_llm

# å¯¼å…¥æ¨¡å—åŒ–çš„ Agent
from chying_agent.agents.advisor import ADVISOR_SYSTEM_PROMPT
from chying_agent.agents.main_agent import MAIN_AGENT_SYSTEM_PROMPT
from chying_agent.agents.poc_agent import POC_AGENT_SYSTEM_PROMPT
from chying_agent.agents.docker_agent import DOCKER_AGENT_SYSTEM_PROMPT
from chying_agent.prompts_book import (
    TOOL_OUTPUT_SUMMARY_PROMPT,
    MAIN_AGENT_PLANNER_PROMPT,
    build_advisor_context,
    build_main_context,
    get_target_url,
    get_target_info,
)

# å¯¼å…¥ Skills åŠ è½½å™¨
from chying_agent.skills.skill_loader import load_skills_for_context, get_skill_summary


# ==================== åˆå§‹åŒ–å…¨å±€é€Ÿç‡é™åˆ¶å™¨ ====================
DEEPSEEK_RPS = float(os.getenv("DEEPSEEK_REQUESTS_PER_SECOND", "2.0"))
MINIMAX_RPS = float(os.getenv("MINIMAX_REQUESTS_PER_SECOND", "2.0"))

deepseek_limiter = get_rate_limiter("deepseek_llm", requests_per_second=DEEPSEEK_RPS, burst_size=5)
minimax_limiter = get_rate_limiter("minimax_llm", requests_per_second=MINIMAX_RPS, burst_size=5)


async def build_multi_agent_graph(config: RunnableConfig):
    """
    æ„å»ºå¤š Agent åä½œå›¾ï¼ˆä¸‰å±‚æ¶æ„ï¼‰

    Args:
        config: LangGraph è¿è¡Œæ—¶é…ç½®

    Returns:
        ç¼–è¯‘åçš„ LangGraph åº”ç”¨
    """
    # ==================== 0. åˆå§‹åŒ– LLM ====================
    from chying_agent.model import create_model
    from chying_agent.core.singleton import get_config_manager
    from langchain_openai import ChatOpenAI

    agent_config = get_config_manager().config

    # ä¸» LLM (DeepSeek) - ç”¨äº Main Agent å’Œæ‰§è¡Œå±‚
    main_llm = create_model(agent_config)
    log_system_event("[Graph V2] åˆå§‹åŒ– main_llm (DeepSeek)")

    # é¡¾é—® LLM (MiniMax)
    advisor_llm = ChatOpenAI(
        base_url=os.getenv("SILICONFLOW_BASE_URL", "https://api.siliconflow.cn/v1"),
        api_key=os.getenv("SILICONFLOW_API_KEY"),
        model=os.getenv("SILICONFLOW_MODEL", "MiniMaxAI/MiniMax-M2"),
        temperature=0.7,
        max_tokens=8192,
        timeout=600,
        max_retries=10
    )
    log_system_event("[Graph V2] åˆå§‹åŒ– advisor_llm (MiniMax)")

    # ä» config ä¸­æå– manual_mode
    manual_mode = False
    if config and hasattr(config, "get"):
        configurable = config.get("configurable", {})
        manual_mode = configurable.get("manual_mode", False)

    return await _build_graph_internal(main_llm, advisor_llm, manual_mode=manual_mode)


async def _build_graph_internal(
    main_llm: BaseChatModel,
    advisor_llm: BaseChatModel,
    manual_mode: bool = False,
    graph_name: str = "LangGraph"
):
    """
    æ„å»ºä¸‰å±‚æ¶æ„å›¾çš„å†…éƒ¨å®ç°

    Args:
        main_llm: ä¸» LLM
        advisor_llm: é¡¾é—® LLM
        manual_mode: æ˜¯å¦æ‰‹åŠ¨æ¨¡å¼
        graph_name: å›¾åç§°ï¼ˆç”¨äº Langfuse trace nameï¼‰
    """
    # ==================== 1. åˆå§‹åŒ–è®°å¿†å’Œå·¥å…· ====================
    memory_store = get_memory_store()
    memory_tools = get_all_memory_tools(manual_mode=manual_mode)
    pentest_tools = get_all_tools()
    all_tools = pentest_tools + memory_tools

    # åˆ†ç¦»å·¥å…·ï¼šPoC Agent ç”¨ execute_python_pocï¼ŒDocker Agent ç”¨ execute_command
    poc_tool = next((t for t in pentest_tools if t.name == "execute_python_poc"), None)
    docker_tool = next((t for t in pentest_tools if t.name == "execute_command"), None)
    submit_tool = next((t for t in memory_tools if t.name == "submit_flag"), None)

    log_system_event(
        f"[Graph V2] åˆå§‹åŒ–ä¸‰å±‚æ¶æ„",
        {
            "poc_tool": poc_tool.name if poc_tool else None,
            "docker_tool": docker_tool.name if docker_tool else None,
            "submit_tool": submit_tool.name if submit_tool else None,
            "manual_mode": manual_mode
        }
    )

    # æ‰§è¡Œå±‚ Agent ç»‘å®šå„è‡ªçš„å·¥å…·
    poc_llm_with_tools = main_llm.bind_tools([poc_tool]) if poc_tool else None
    docker_llm_with_tools = main_llm.bind_tools([docker_tool]) if docker_tool else None

    # åˆ›å»º ToolNode ç”¨äºæ‰§è¡Œå·¥å…·
    base_tool_node = ToolNode(all_tools)

    # ==================== 2. Advisor Agent èŠ‚ç‚¹ ====================
    async def advisor_node(state: PenetrationTesterState):
        """
        é¡¾é—® Agent - æä¾›æ”»å‡»å»ºè®® + æŒ‰éœ€åŠ è½½ Skills
        """
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        advisor_sys_prompt = ADVISOR_SYSTEM_PROMPT

        # â­ æŒ‰éœ€åŠ è½½ Skills
        hint_content = ""
        target_info_msg = ""
        if state.get("current_challenge"):
            challenge = state["current_challenge"]
            hint_content = challenge.get("hint_content", "")
            target_info = challenge.get("target_info", {})
            ip = target_info.get("ip", "unknown")
            ports = target_info.get("port", [])
            target_info_msg = f"- **ç›®æ ‡**: {ip}:{','.join(map(str, ports))}"

        # åŠ è½½ç›¸å…³ Skills
        skills_content = load_skills_for_context(
            hint=hint_content,
            max_skills=2
        )

        if skills_content:
            advisor_sys_prompt += f"\n\n---\n\n# æ¼æ´çŸ¥è¯†åº“ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰\n\n{skills_content}"
            log_system_event("[Advisor] å·²åŠ è½½æ¼æ´çŸ¥è¯†åº“")

        if hint_content:
            advisor_sys_prompt += f"\n## ç›®æ ‡##\n{target_info_msg}\n## é¢˜ç›®æç¤º(**éå¸¸é‡è¦**): \n\n{hint_content}\n\n"

        advisor_messages = [SystemMessage(content=advisor_sys_prompt)]

        # æ„å»ºåŠ¨æ€ä¸Šä¸‹æ–‡
        context_parts = build_advisor_context(state)

        if context_parts:
            full_context = "\n".join(context_parts) + "\n\n---\n\nè¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œæä¾›ä½ çš„æ”»å‡»å»ºè®®ã€‚"
            advisor_messages.append(HumanMessage(content=full_context))
        else:
            advisor_messages.append(HumanMessage(content="ä¸»æ”»å‡»æ‰‹å°šæœªé€‰æ‹©é¢˜ç›®æˆ–å¼€å§‹æ”»å‡»ã€‚è¯·ç­‰å¾…è¿›ä¸€æ­¥ä¿¡æ¯ã€‚"))

        log_agent_thought("[Advisor] å¼€å§‹åˆ†æ...")

        try:
            advisor_response: AIMessage = await retry_llm_call(
                advisor_llm.ainvoke,
                advisor_messages,
                max_retries=5,
                base_delay=2.0,
                limiter=minimax_limiter
            )
        except Exception as e:
            log_system_event(
                "[Advisor] âŒ LLM è°ƒç”¨å¤±è´¥",
                {"error": str(e)},
                level=logging.ERROR
            )
            return {
                "advisor_suggestion": "",
                "messages": []
            }

        log_agent_thought(
            "[MiniMax] æä¾›å»ºè®®",
            {"advice": advisor_response.content[:200] + "..."}
        )

        return {
            "advisor_suggestion": advisor_response.content,
            "messages": []
        }

    # ==================== 3. Main Agent èŠ‚ç‚¹ï¼ˆè§„åˆ’æ¨¡å¼ï¼‰====================
    async def main_agent_node(state: PenetrationTesterState):
        """
        ä¸» Agent - è§„åˆ’ä¸å†³ç­–ï¼ˆä¸ç›´æ¥æ‰§è¡Œå·¥å…·ï¼‰

        è¾“å‡ºæ ¼å¼ï¼š
        - [DISPATCH_TASK] ... [/DISPATCH_TASK]ï¼šåˆ†å‘ä»»åŠ¡ç»™æ‰§è¡Œå±‚
        - [REQUEST_ADVISOR_HELP]ï¼šè¯·æ±‚é¡¾é—®å¸®åŠ©
        - [SUBMIT_FLAG:flag{{...}}]ï¼šæäº¤ FLAGï¼ˆèŠ±æ‹¬å·å†…å¡«å†™å®é™…FLAGå†…å®¹ï¼‰
        """
        # æ„å»ºå½“å‰ä¸Šä¸‹æ–‡
        current_context = build_main_context(state)

        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = MAIN_AGENT_PLANNER_PROMPT.format(current_context=current_context)

        # æ·»åŠ é¡¾é—®å»ºè®®
        advisor_suggestion = state.get("advisor_suggestion")
        if advisor_suggestion:
            system_prompt += f"""

---

## ğŸ¤ é¡¾é—®å»ºè®®

{advisor_suggestion}

**è¯·å‚è€ƒé¡¾é—®å»ºè®®ï¼Œåˆ¶å®šä½ çš„æ”»å‡»è®¡åˆ’ã€‚**
"""

        messages = [SystemMessage(content=system_prompt)]

        # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆé™åˆ¶æ•°é‡ï¼‰
        history = list(state.get("messages", []))
        max_history = int(os.getenv("MAX_HISTORY_MESSAGES", "10"))
        if len(history) > max_history:
            history = history[-max_history:]

        messages.extend(history)

        log_agent_thought("[Main Agent] å¼€å§‹è§„åˆ’...")

        try:
            ai_message: AIMessage = await retry_llm_call(
                main_llm.ainvoke,  # ä¸ç»‘å®šå·¥å…·ï¼Œçº¯è§„åˆ’æ¨¡å¼
                messages,
                max_retries=5,
                base_delay=2.0,
                limiter=deepseek_limiter
            )
        except Exception as e:
            log_system_event(
                "[Main Agent] âŒ LLM è°ƒç”¨å¤±è´¥",
                {"error": str(e)},
                level=logging.ERROR
            )
            return {
                "messages": [AIMessage(content=f"è§„åˆ’å¤±è´¥ï¼š{str(e)} [REQUEST_ADVISOR_HELP]")],
                "advisor_suggestion": "",
                "request_advisor_help": True
            }

        content = ai_message.content or ""

        # è§£æè¾“å‡º
        request_help = "[REQUEST_ADVISOR_HELP]" in content
        dispatch_task = _parse_dispatch_task(content)
        submit_flag = _parse_submit_flag(content)

        log_agent_thought(
            "[Main Agent] è§„åˆ’ç»“æœ",
            {
                "has_dispatch": dispatch_task is not None,
                "has_submit": submit_flag is not None,
                "request_help": request_help
            }
        )

        # å­˜å‚¨åˆ†å‘ä»»åŠ¡åˆ°çŠ¶æ€
        result = {
            "messages": [ai_message],
            "advisor_suggestion": "",
            "request_advisor_help": request_help
        }

        if dispatch_task:
            result["pending_task"] = dispatch_task

        if submit_flag:
            result["pending_flag"] = submit_flag

        return result

    # ==================== 4. PoC Agent èŠ‚ç‚¹ ====================
    async def poc_agent_node(state: PenetrationTesterState):
        """
        PoC Agent - æ‰§è¡Œ Python è„šæœ¬

        å¤„ç†ä¸¤ç§æƒ…å†µï¼š
        1. pending_flag: Main Agent è§£æå‡ºçš„ FLAGï¼Œéœ€è¦ç›´æ¥æäº¤
        2. pending_task: éœ€è¦æ‰§è¡Œçš„ Python PoC ä»»åŠ¡
        """
        # ä¼˜å…ˆå¤„ç† pending_flagï¼ˆMain Agent è§£æå‡ºçš„ FLAGï¼‰
        pending_flag = state.get("pending_flag")
        if pending_flag:
            if submit_tool:
                log_system_event(f"[PoC Agent] æäº¤ FLAG: {pending_flag[:20]}...")
                challenge = state.get("current_challenge", {})
                challenge_code = challenge.get("challenge_code", challenge.get("code", "unknown"))

                # æ„é€ å·¥å…·è°ƒç”¨æ¶ˆæ¯
                tool_call_id = f"submit_flag_{challenge_code}"
                ai_message = AIMessage(
                    content="",
                    tool_calls=[{
                        "id": tool_call_id,
                        "name": "submit_flag",
                        "args": {
                            "challenge_code": challenge_code,
                            "flag": pending_flag
                        }
                    }]
                )
                return {
                    "messages": [ai_message],
                    "pending_flag": None,  # æ¸…é™¤å·²å¤„ç†çš„ FLAG
                    "pending_task": None
                }
            else:
                # æ‰‹åŠ¨æ¨¡å¼ï¼šæ²¡æœ‰ submit_toolï¼Œç›´æ¥è¾“å‡º FLAG å¹¶æ ‡è®°å®Œæˆ
                log_system_event(f"[PoC Agent] æ‰‹åŠ¨æ¨¡å¼ - å‘ç° FLAG: {pending_flag}")
                ai_message = AIMessage(
                    content=f"ğŸ‰ å‘ç° FLAG: {pending_flag}\n\nï¼ˆæ‰‹åŠ¨æ¨¡å¼ï¼Œè¯·è‡ªè¡Œæäº¤ï¼‰"
                )
                return {
                    "messages": [ai_message],
                    "pending_flag": None,
                    "pending_task": None,
                    "flag": pending_flag,
                    "is_finished": True
                }

        pending_task = state.get("pending_task") or {}
        task_description = pending_task.get("task", "")

        if not task_description:
            log_system_event("[PoC Agent] æ²¡æœ‰å¾…æ‰§è¡Œçš„ä»»åŠ¡")
            return {"messages": [], "pending_task": None}

        # æ„å»ºæç¤ºè¯
        target_url = get_target_url(state)
        hint_content = ""
        if state.get("current_challenge"):
            hint_content = state["current_challenge"].get("hint_content", "")

        prompt = f"""
{POC_AGENT_SYSTEM_PROMPT}

---

## å½“å‰ä»»åŠ¡

{task_description}

## ç›®æ ‡ä¿¡æ¯

- **URL**: {target_url}
{"- **æç¤º**: " + hint_content if hint_content else ""}

è¯·ç¼–å†™å¹¶æ‰§è¡Œ Python PoC ä»£ç æ¥å®Œæˆä»»åŠ¡ã€‚
"""

        messages = [
            SystemMessage(content=prompt),
            HumanMessage(content="è¯·æ‰§è¡Œä»»åŠ¡ã€‚")
        ]

        log_agent_thought(f"[PoC Agent] æ‰§è¡Œä»»åŠ¡: {task_description[:100]}...")

        try:
            ai_message: AIMessage = await retry_llm_call(
                poc_llm_with_tools.ainvoke,
                messages,
                max_retries=3,
                base_delay=1.0,
                limiter=deepseek_limiter
            )
        except Exception as e:
            log_system_event(
                "[PoC Agent] âŒ LLM è°ƒç”¨å¤±è´¥",
                {"error": str(e)},
                level=logging.ERROR
            )
            return {
                "messages": [AIMessage(content=f"PoC æ‰§è¡Œå¤±è´¥ï¼š{str(e)}")],
                "pending_task": None
            }

        return {
            "messages": [ai_message],
            "pending_task": None  # æ¸…é™¤å·²å¤„ç†çš„ä»»åŠ¡
        }

    # ==================== 5. Docker Agent èŠ‚ç‚¹ ====================
    async def docker_agent_node(state: PenetrationTesterState):
        """
        Docker Agent - æ‰§è¡Œ Kali å·¥å…·
        """
        pending_task = state.get("pending_task") or {}
        task_description = pending_task.get("task", "")

        if not task_description:
            log_system_event("[Docker Agent] æ²¡æœ‰å¾…æ‰§è¡Œçš„ä»»åŠ¡")
            return {"messages": [], "pending_task": None}

        # æ„å»ºæç¤ºè¯
        target_info = get_target_info(state)
        hint_content = ""
        if state.get("current_challenge"):
            hint_content = state["current_challenge"].get("hint_content", "")

        prompt = f"""
{DOCKER_AGENT_SYSTEM_PROMPT}

---

## å½“å‰ä»»åŠ¡

{task_description}

## ç›®æ ‡ä¿¡æ¯

{target_info}
{"- **æç¤º**: " + hint_content if hint_content else ""}

è¯·æ‰§è¡Œé€‚å½“çš„ Kali å·¥å…·å‘½ä»¤æ¥å®Œæˆä»»åŠ¡ã€‚
"""

        messages = [
            SystemMessage(content=prompt),
            HumanMessage(content="è¯·æ‰§è¡Œä»»åŠ¡ã€‚")
        ]

        log_agent_thought(f"[Docker Agent] æ‰§è¡Œä»»åŠ¡: {task_description[:100]}...")

        try:
            ai_message: AIMessage = await retry_llm_call(
                docker_llm_with_tools.ainvoke,
                messages,
                max_retries=3,
                base_delay=1.0,
                limiter=deepseek_limiter
            )
        except Exception as e:
            log_system_event(
                "[Docker Agent] âŒ LLM è°ƒç”¨å¤±è´¥",
                {"error": str(e)},
                level=logging.ERROR
            )
            return {
                "messages": [AIMessage(content=f"Docker æ‰§è¡Œå¤±è´¥ï¼š{str(e)}")],
                "pending_task": None
            }

        return {
            "messages": [ai_message],
            "pending_task": None
        }

    # ==================== 6. Tool æ‰§è¡ŒèŠ‚ç‚¹ ====================
    async def tool_node(state: PenetrationTesterState):
        """
        å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ - æ‰§è¡Œ PoC Agent æˆ– Docker Agent çš„å·¥å…·è°ƒç”¨
        """
        # æ‰§è¡Œå·¥å…·
        result = await base_tool_node.ainvoke(state)

        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ° FLAG
        if "messages" in result:
            for msg in result["messages"]:
                if hasattr(msg, "content") and msg.content:
                    if "ç­”æ¡ˆæ­£ç¡®" in msg.content:
                        # æå– FLAG
                        messages = state.get("messages", [])
                        if messages:
                            last_message = messages[-1]
                            if hasattr(last_message, "tool_calls") and last_message.tool_calls:
                                for tool_call in last_message.tool_calls:
                                    if tool_call.get("name") == "submit_flag":
                                        submitted_flag = tool_call.get("args", {}).get("flag")
                                        if submitted_flag:
                                            result["flag"] = submitted_flag
                                            result["is_finished"] = True
                                            result["consecutive_failures"] = 0
                                            return result

        # æ£€æµ‹å¤±è´¥
        is_failure = False
        if "messages" in result:
            for msg in result["messages"]:
                if hasattr(msg, "content") and msg.content:
                    content = msg.content.lower()
                    failure_keywords = ["error", "failed", "exception", "æ— æ³•", "é”™è¯¯", "å¤±è´¥"]
                    is_failure = any(kw in content for kw in failure_keywords)

        consecutive_failures = state.get("consecutive_failures", 0)
        if is_failure:
            consecutive_failures += 1
        else:
            consecutive_failures = 0

        result["consecutive_failures"] = consecutive_failures

        return result

    # ==================== 7. è·¯ç”±å‡½æ•° ====================
    def route_after_main(state: PenetrationTesterState) -> Literal["poc_agent", "docker_agent", "advisor", "end"]:
        """
        Main Agent ä¹‹åçš„è·¯ç”±
        """
        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if state.get("flag") or state.get("is_finished"):
            return "end"

        # æ£€æŸ¥æ˜¯å¦è¯·æ±‚å¸®åŠ©
        if state.get("request_advisor_help"):
            return "advisor"

        # æ£€æŸ¥æ˜¯å¦æœ‰å¾…åˆ†å‘çš„ä»»åŠ¡
        pending_task = state.get("pending_task")
        if pending_task:
            agent = pending_task.get("agent", "poc")
            if agent == "docker":
                log_system_event("[Router] åˆ†å‘ä»»åŠ¡åˆ° Docker Agent")
                return "docker_agent"
            else:
                log_system_event("[Router] åˆ†å‘ä»»åŠ¡åˆ° PoC Agent")
                return "poc_agent"

        # æ£€æŸ¥æ˜¯å¦æœ‰å¾…æäº¤çš„ FLAG
        pending_flag = state.get("pending_flag")
        if pending_flag:
            # ç›´æ¥æäº¤ FLAGï¼ˆé€šè¿‡ PoC Agentï¼‰
            return "poc_agent"

        # é»˜è®¤è¿”å› advisor
        return "advisor"

    def route_after_execution(state: PenetrationTesterState) -> Literal["tools", "main_agent", "end"]:
        """
        æ‰§è¡Œå±‚ Agent ä¹‹åçš„è·¯ç”±
        """
        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if state.get("flag") or state.get("is_finished"):
            return "end"

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        messages = state.get("messages", [])
        if messages:
            last_message = messages[-1]
            if hasattr(last_message, "tool_calls") and last_message.tool_calls:
                return "tools"

        # è¿”å› Main Agent ç»§ç»­è§„åˆ’
        return "main_agent"

    def route_after_tools(state: PenetrationTesterState) -> Literal["main_agent", "advisor", "end"]:
        """
        å·¥å…·æ‰§è¡Œåçš„è·¯ç”±
        """
        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if state.get("flag") or state.get("is_finished"):
            return "end"

        # æ£€æŸ¥æ˜¯å¦è¶…é™
        messages = state.get("messages", [])
        attempts = len([m for m in messages if hasattr(m, 'tool_calls') and m.tool_calls])

        from chying_agent.core.constants import AgentConfig
        max_attempts = AgentConfig.get_max_attempts()

        if attempts > max_attempts:
            return "end"

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ Advisor
        consecutive_failures = state.get("consecutive_failures", 0)
        from chying_agent.core.constants import SmartRoutingConfig
        failures_threshold = SmartRoutingConfig.get_failures_threshold()

        if consecutive_failures > 0 and consecutive_failures % failures_threshold == 0:
            return "advisor"

        # è¿”å› Main Agent
        return "main_agent"

    # ==================== 8. æ„å»º StateGraph ====================
    workflow = StateGraph(PenetrationTesterState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("advisor", advisor_node)
    workflow.add_node("main_agent", main_agent_node)
    workflow.add_node("poc_agent", poc_agent_node)
    workflow.add_node("docker_agent", docker_agent_node)
    workflow.add_node("tools", tool_node)

    # è®¾ç½®å…¥å£
    workflow.set_entry_point("advisor")

    # å®šä¹‰è¾¹
    workflow.add_edge("advisor", "main_agent")

    workflow.add_conditional_edges(
        "main_agent",
        route_after_main,
        {
            "poc_agent": "poc_agent",
            "docker_agent": "docker_agent",
            "advisor": "advisor",
            "end": END
        }
    )

    workflow.add_conditional_edges(
        "poc_agent",
        route_after_execution,
        {
            "tools": "tools",
            "main_agent": "main_agent",
            "end": END
        }
    )

    workflow.add_conditional_edges(
        "docker_agent",
        route_after_execution,
        {
            "tools": "tools",
            "main_agent": "main_agent",
            "end": END
        }
    )

    workflow.add_conditional_edges(
        "tools",
        route_after_tools,
        {
            "main_agent": "main_agent",
            "advisor": "advisor",
            "end": END
        }
    )

    # ç¼–è¯‘å›¾ï¼ˆä¼ å…¥ name å‚æ•°ï¼Œç”¨äº Langfuse trace nameï¼‰
    app = workflow.compile(store=memory_store, name=graph_name)

    log_system_event("[Graph V2] ä¸‰å±‚æ¶æ„å›¾æ„å»ºå®Œæˆ")
    return app


# ==================== è¾…åŠ©å‡½æ•° ====================


def _parse_dispatch_task(content: str) -> Optional[dict]:
    """è§£æä»»åŠ¡åˆ†å‘æŒ‡ä»¤"""
    import re

    pattern = r'\[DISPATCH_TASK\]\s*agent:\s*(\w+)\s*task:\s*\|?\s*(.*?)\[/DISPATCH_TASK\]'
    match = re.search(pattern, content, re.DOTALL)

    if match:
        return {
            "agent": match.group(1).strip().lower(),
            "task": match.group(2).strip()
        }

    return None


def _parse_submit_flag(content: str) -> Optional[str]:
    """è§£æ FLAG æäº¤æŒ‡ä»¤"""
    import re

    pattern = r'\[SUBMIT_FLAG:(.*?)\]'
    match = re.search(pattern, content)

    if match:
        return match.group(1).strip()

    return None


# ==================== å…¼å®¹æ€§åŒ…è£… ====================

async def build_multi_agent_graph_with_llms(
    main_llm: BaseChatModel,
    advisor_llm: BaseChatModel,
    manual_mode: bool = False,
    graph_name: str = "LangGraph"
):
    """
    æ„å»ºä¸‰å±‚æ¶æ„å›¾ï¼ˆæ”¯æŒä¼ å…¥è‡ªå®šä¹‰ LLMï¼‰

    Args:
        main_llm: ä¸» LLM
        advisor_llm: é¡¾é—® LLM
        manual_mode: æ˜¯å¦æ‰‹åŠ¨æ¨¡å¼
        graph_name: å›¾åç§°ï¼ˆç”¨äº Langfuse trace nameï¼‰
    """
    return await _build_graph_internal(main_llm, advisor_llm, manual_mode=manual_mode, graph_name=graph_name)
